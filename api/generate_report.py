# -*- coding: utf-8 -*-
"""
í†µí•© ë¦¬í¬íŠ¸ ìƒì„±ê¸° (ì£¼ê°„/ì›”ê°„ ë¦¬í¬íŠ¸ í†µí•©)
- ê¾¸ì¤€í•¨ ì§€ìˆ˜ + ì•„ì´ì½˜ + summary + recommendation (weekly/monthly ê³µí†µ êµ¬ì¡°)
- summary 4ë¬¸ì¥ì— BJ Fogg í–‰ë™ëª¨ë¸(B=MAP) í†¤ ë°˜ì˜ (spark/facilitator/signal)
"""

import os
import json
import re
from datetime import datetime, timedelta
from collections import Counter
from dotenv import load_dotenv

# ===== í™˜ê²½ ë³€ìˆ˜ / ê²½ë¡œ ì„¤ì • =====
load_dotenv()
INPUT_DIR = "data"
OUTPUT_DIRS = {
    "weekly": "outputs/weekly_report",
    "monthly": "outputs/monthly_report",
}
for _d in OUTPUT_DIRS.values():
    os.makedirs(_d, exist_ok=True)

# ===== ê¾¸ì¤€í•¨ ì§€ìˆ˜ / ì´ëª¨ì§€ ë§¤í•‘ =====
CONSISTENCY_THRESHOLDS = {"high": 70, "medium": 40}
REASON_ICON_MAP = {
    "ì˜ì§€ ë¶€ì¡±": "ğŸ˜©",
    "ê±´ê°• ë¬¸ì œ": "ğŸ¤’",
    "ê³¼ë„í•œ ëª©í‘œ ì„¤ì •": "ğŸ¯",
    "ì‹œê°„ ë¶€ì¡±": "â°",
    "ì¼ì • ì¶©ëŒ": "ğŸ“…",
    "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)": "ğŸ’¬",
}

# ===== ììœ ì…ë ¥ ì´ëª¨ì§€ ì¶”ë¡  =====
def guess_emoji_from_text(text: str) -> str:
    t = (text or "").lower().strip()
    if re.search(r"(ê·¼ìœ¡|í†µì¦|ìš´ë™|í”¼ë¡œ|ëª¸|ìŠ¤íŠ¸ë ˆì¹­)", t): return "ğŸ’ª"
    if re.search(r"(ë¹„|rain|ì¥ë§ˆ|ìš°ì‚°)", t): return "ğŸŒ§ï¸"
    if re.search(r"(ë”ì›€|hot|heat|í­ì—¼|ë¥)", t): return "â˜€ï¸"
    if re.search(r"(ì¶”ì›€|cold|snow|í•œíŒŒ|ì¶¥)", t): return "ğŸ¥¶"
    if re.search(r"(í”¼ê³¤|ì¡¸|ìˆ˜ë©´|ì»¨ë””ì…˜|sleep|tired)", t): return "ğŸ˜´"
    if re.search(r"(ê³µë¶€|ì‹œí—˜|ìˆ™ì œ|ê³¼ì œ|project|work)", t): return "ğŸ“š"
    if re.search(r"(ì•½ì†|ì¹œêµ¬|ëª¨ì„|í–‰ì‚¬|ë°ì´íŠ¸|ë§Œë‚¨)", t): return "ğŸ§‘â€ğŸ¤â€ğŸ§‘"
    if re.search(r"(ì§€ê°|ì‹œê°„|ëŠ¦|ì¶œê·¼|ë“±êµ)", t): return "â°"
    if re.search(r"(ìš°ìš¸|ê¸°ë¶„|ì§œì¦|í™”|sad|depress)", t): return "ğŸ˜"
    return "ğŸ’¬"

# ===== ì‹œê°„ ìœ í‹¸ =====
def parse_hhmm(s: str):
    """
    ì…ë ¥: 'HH:MM' ë˜ëŠ” 'HH:MM:SS' ëª¨ë‘ í—ˆìš©
    ë°˜í™˜: ì˜¤ëŠ˜ ë‚ ì§œì˜ datetime (ì‹œê°„/ë¶„ë§Œ ì‚¬ìš©)
    """
    t = (s or "").strip()
    for fmt in ("%H:%M", "%H:%M:%S"):
        try:
            tm = datetime.strptime(t, fmt).time()
            # secondsëŠ” ë²„ë¦¬ê³  ë¶„ ë‹¨ìœ„ê¹Œì§€ë§Œ ì‚¬ìš©
            tm = tm.replace(second=0, microsecond=0)
            return datetime.combine(datetime.today().date(), tm)
        except ValueError:
            continue

    # ì—¬ì „íˆ ì‹¤íŒ¨í•˜ë©´ ì½œë¡  ë¶„í•´ë¡œ ìµœí›„ ì‹œë„
    try:
        parts = [int(p) for p in t.split(":")]
        if len(parts) >= 2:
            hh, mm = parts[0], parts[1]
            return datetime.combine(datetime.today().date(),
                                    datetime.strptime(f"{hh:02d}:{mm:02d}", "%H:%M").time())
    except Exception:
        pass
    raise ValueError(f"Invalid time format: {s!r} (expected HH:MM or HH:MM:SS)")

def normalize_hhmm(s: str) -> str:
    """'HH:MM' ë˜ëŠ” 'HH:MM:SS' -> í•­ìƒ 'HH:MM'"""
    dt = parse_hhmm(s)
    return dt.strftime("%H:%M")

def minutes_between(start_hhmm: str, end_hhmm: str) -> int:
    delta = parse_hhmm(end_hhmm) - parse_hhmm(start_hhmm)
    return max(int(delta.total_seconds() // 60), 0)

def add_minutes(hhmm: str, delta: int) -> str:
    return (parse_hhmm(hhmm) + timedelta(minutes=delta)).strftime("%H:%M")

def extract_all_logs(logs):
    """Return all logs without date filtering"""
    return logs

def minutes_filter_copy(habits):
    """Copy habits with all logs, no date filtering"""
    out = []
    for h in habits:
        out.append({
            "habit_id": h.get("habit_id"),
            "name": h.get("name"),
            "day_of_week": h.get("day_of_week", []),
            "start_time": h.get("start_time"),
            "end_time": h.get("end_time"),
            "habit_log": extract_all_logs(h.get("habit_log", [])),
        })
    return out

# ===== ì‹¤íŒ¨ ì‚¬ìœ  ì •ê·œí™” =====
CATEGORY_RULES = [
    (r"(ì˜ìš•|ë™ê¸°|í•˜ê¸°\s*ì‹«|ë¯¸ë£¨|ê·€ì°®|ì˜ì§€\s*ë¶€ì¡±)", "ì˜ì§€ ë¶€ì¡±"),
    (r"(í”¼ê³¤|ìˆ˜ë©´|ì¡¸ë¦¼|ëŠ¦ì |ì•ŒëŒ|ì»¨ë””ì…˜|ê°ê¸°|í†µì¦|ê³¼ë¡œ)", "ê±´ê°• ë¬¸ì œ"),
    (r"(ê³¼ë„|ë¬´ë¦¬|ë²„ê²|ë¶€ë‹´|ê°•ë„\s*ë†’|ì‹œê°„\s*ê¸¸|ë¹¡ì„¸)", "ê³¼ë„í•œ ëª©í‘œ ì„¤ì •"),
    (r"(ì‹œê°„\s*ë¶€ì¡±|ë°”ì¨|ì—…ë¬´|ê³¼ì œ|ì‹œí—˜|ë§ˆê°|ì¶œê·¼|ë“±êµ)", "ì‹œê°„ ë¶€ì¡±"),
    (r"(ì¼ì •\s*ì¶©ëŒ|ì™¸ì¶œ|ì•½ì†|ëª¨ì„|ì—¬í–‰|ì£¼ë§|ê³µíœ´ì¼)", "ì¼ì • ì¶©ëŒ"),
    (r"(ë‚ ì”¨|ë”ì›€|ì¶”ì›€|ë¹„|í­ì—¼|í­ìš°|í•œíŒŒ|ìš°ìš¸|ê¸°ë¶„|ì§œì¦|í™”)", "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)"),
]
def normalize_reason_category(text: str) -> str:
    t = (text or "").lower().strip()
    for pat, label in CATEGORY_RULES:
        if re.search(pat, t):
            return label
    return "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)"

# ===== ì§€ìˆ˜ ê³„ì‚° =====
def compute_overall_success_rate(habits):
    total, success = 0, 0
    for h in habits:
        logs = h.get("habit_log", [])
        total += len(logs)
        success += sum(1 for l in logs if l.get("completed"))
    return (success / total * 100) if total else 0.0

def consistency_level_from_rate(rate):
    if rate >= CONSISTENCY_THRESHOLDS["high"]: return "ë†’ìŒ"
    if rate >= CONSISTENCY_THRESHOLDS["medium"]: return "ë³´í†µ"
    return "ë‚®ìŒ"

# ===== ì‹¤íŒ¨ ì‚¬ìœ  ì§‘ê³„ =====
def compute_per_habit_top_failure_reasons(active_habits, topk=2):
    result = []
    for h in active_habits:
        hid = h.get("habit_id")
        name = h.get("name") or ""
        logs = h.get("habit_log", [])
        counter, user_texts = Counter(), []
        for log in logs:
            if log.get("completed"): continue
            for raw in (log.get("failure_reason") or []):
                label = normalize_reason_category(raw)
                counter[label] += 1
                if label == "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)": user_texts.append(raw.strip())
        top_labels = [lbl for lbl, _ in counter.most_common(topk)]
        final_reasons = []
        if "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)" in top_labels and user_texts:
            user_texts = [t for t, _ in Counter(user_texts).most_common(topk)]
            for lbl in top_labels:
                if lbl == "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)": final_reasons.extend(user_texts)
                else: final_reasons.append(lbl)
        else:
            final_reasons = top_labels[:topk]
        reasons = []
        for r in final_reasons:
            norm = normalize_reason_category(r)
            icon = guess_emoji_from_text(r) if norm == "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)" else REASON_ICON_MAP.get(norm, "ğŸ’¬")
            reasons.append({"reason": r, "icon": icon})
        result.append({"habit_id": hid, "name": name, "reasons": reasons})
    return result

# ===== MAP ì§„ë‹¨ ìœ í‹¸ (ìš”ì•½ ì¹´í”¼ìš©, ìµœì†Œ ë³€ê²½) =====
def _collect_fail_labels_from_habits(habits):
    labels = []
    total, success = 0, 0
    for h in habits:
        logs = h.get("habit_log", [])
        total += len(logs)
        success += sum(1 for l in logs if l.get("completed"))
        for l in logs:
            if l.get("completed"):
                continue
            for raw in (l.get("failure_reason") or []):
                labels.append(normalize_reason_category(raw))
    rate = (success / total) if total else 0.0
    return labels, rate

def infer_overall_map_state(habits, overall_rate: float):
    """
    habitsì™€ ì „ì²´ ì„±ê³µë¥ ë¡œ ë™ê¸°/ëŠ¥ë ¥ ìƒíƒœë¥¼ ê°„ë‹¨íˆ ì¶”ì •í•´
    ìš”ì•½ ì¹´í”¼ í†¤ì„ ê²°ì •(spark/facilitator/signal)í•˜ëŠ” íœ´ë¦¬ìŠ¤í‹±.
    """
    labels, _ = _collect_fail_labels_from_habits(habits)
    c = Counter(labels)

    # Ability ë‚®ìŒ ì‹ í˜¸: ì‹œê°„/ì¼ì •/ê³¼ë„ ëª©í‘œ
    ability_low = c["ì‹œê°„ ë¶€ì¡±"] + c["ì¼ì • ì¶©ëŒ"] + c["ê³¼ë„í•œ ëª©í‘œ ì„¤ì •"]
    # Motivation ë‚®ìŒ ì‹ í˜¸: ì˜ì§€ ë¶€ì¡±
    motivation_low = c["ì˜ì§€ ë¶€ì¡±"]

    ability = "low" if ability_low >= 2 else ("medium" if ability_low == 1 else "high")
    # ì„±ê³µë¥ ì´ ë§ì´ ë‚®ìœ¼ë©´ ë™ê¸° ì €í•˜ë¡œ ê°€ì •
    motivation = "low" if motivation_low >= 2 else ("medium" if motivation_low == 1 else ("low" if overall_rate < 30 else "high"))

    if motivation == "low":
        prompt = "spark"         # ì˜ì§€ ë¶ˆë¶™ì´ê¸°
    elif ability == "low":
        prompt = "facilitator"   # ë‚œì´ë„/ë³µì¡ë„ ë‚®ì¶”ê¸°
    else:
        prompt = "signal"        # ì¡°ìš©í•œ 'ì§€ê¸ˆ ì‹œì‘' ì‹ í˜¸

    return {"motivation": motivation, "ability": ability, "prompt_type": prompt}

# ===== summary ìƒì„± (B=MAP ì¹´í”¼ ë°˜ì˜) =====
def flatten_reasons_from_top_fail(failure_data):
    out = []
    for h in (failure_data or []):
        for r in h.get("reasons", []):
            if isinstance(r, list) and r: out.append(r[0])
    return out

def generate_summary(nickname, habits, failure_data, rate):
    """
    ì£¼ê°„/ì›”ê°„ ê³µí†µ summary ìƒì„±
    - success_rate(ì „ì²´ ê¾¸ì¤€í•¨ ì§€ìˆ˜) + B=MAP(í”„ë¡¬í”„íŠ¸ í†¤) ë°˜ì˜ ì¹´í”¼
    - ì¶œë ¥: {consistency, failure_reasons, daily_pattern, courage}
    """
    # MAP ìƒíƒœ ì¶”ì •(ìš”ì•½ ì¹´í”¼ í†¤ ê²°ì •)
    map_state = infer_overall_map_state(habits, rate)  # {'motivation','ability','prompt_type'}
    pt = map_state["prompt_type"]

    # 1ï¸âƒ£ ê¾¸ì¤€í•¨ ë¬¸ì¥ (+ í”„ë¡¬í”„íŠ¸ í†¤ ê¼¬ë¦¬ë¬¸ì¥)
    consistency = (
        f"ë°”ìœ ê¸°ê°„ ì†ì—ì„œ {rate:.1f}%ë‚˜ í•´ëƒˆë‹¤ëŠ” ê±´ {nickname}ë‹˜ì˜ ê¾¸ì¤€í•¨ì´ ë‹ë³´ì…ë‹ˆë‹¤."
        if rate > 40 else
        "ì´ë²ˆ ê¸°ê°„ì€ ìƒˆë¡œìš´ ì‹œì‘ì„ ìœ„í•œ ì¤€ë¹„ ê¸°ê°„ì´ì—ˆì–´ìš”."
    )

    # 2ï¸âƒ£ ì£¼ìš” ì‹¤íŒ¨ ì›ì¸ (í•„ìš” ì‹œ Tiny ì œì•ˆ í•œ ì¤„)
    all_reasons = flatten_reasons_from_top_fail(failure_data)
    if all_reasons:
        most_common, _ = Counter(all_reasons).most_common(1)[0]
        norm = normalize_reason_category(most_common)
        if norm == "ê¸°íƒ€ (ì§ì ‘ ì…ë ¥)":
            icon = guess_emoji_from_text(most_common)
            failure_reasons = f"{icon} ì§ì ‘ ì…ë ¥ëœ ì‚¬ìœ ê°€ ë§ì•˜ì–´ìš”. ì˜ˆ: \"{most_common}\""
        else:
            icon = REASON_ICON_MAP.get(norm, "ğŸ’¬")
            failure_reasons = f"ê°€ì¥ ìì£¼ ë“±ì¥í•œ ë°©í•´ ìš”ì¸ì€ {icon} '{most_common}'ì´ì—ìš”."
        # Ability ë‚®ìŒ(í¼ì‹¤ë¦¬í…Œì´í„°)ì¼ ë• 'ê°€ë²¼ìš´ ëŒ€ì•ˆ'ì„ ì§§ê²Œ ì œì•ˆ
        if pt == "facilitator":
            failure_reasons += " â†’ ì´ë²ˆ ì£¼ëŠ” '5ë¶„ë§Œ/í•œ ë‹¨ê³„ë§Œ'ìœ¼ë¡œ ê°€ë³ê²Œ ì‹œì‘í•´ë´ìš”."
    else:
        failure_reasons = "ì´ë²ˆ ê¸°ê°„ì€ í° ë°©í•´ ì—†ì´ ì˜ ì´ì–´ì¡Œì–´ìš”."

    # 3ï¸âƒ£ ìš”ì¼ íŒ¨í„´ (ê·¸ëŒ€ë¡œ)
    weekday_success, weekday_total = Counter(), Counter()
    for h in habits:
        for log in h.get("habit_log", []):
            try: day = datetime.strptime(log["date"], "%Y-%m-%d").weekday()
            except Exception: continue
            weekday_total[day] += 1
            if log.get("completed"): weekday_success[day] += 1

    if weekday_total:
        rate_by_day = {d: weekday_success[d] / weekday_total[d] for d in weekday_total}
        best_day = max(rate_by_day, key=rate_by_day.get)
        worst_day = min(rate_by_day, key=rate_by_day.get)
        days = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]
        daily_pattern = f"{days[best_day]}ìš”ì¼ì—” ë¦¬ë“¬ì´ ì¢‹ê³ , {days[worst_day]}ìš”ì¼ì—” ì•½ê°„ ëŠìŠ¨í–ˆì–´ìš”."
    else:
        daily_pattern = "ìš”ì¼ë³„ íŒ¨í„´ì„ í™•ì¸í•  ë°ì´í„°ê°€ ë¶€ì¡±í–ˆì–´ìš”."

    # 4ï¸âƒ£ ì‘ì› ë¬¸ì¥(í”„ë¡¬í”„íŠ¸ í†¤ë³„ ì¹´í”¼)
    courage = {
        "spark": "ì‘ì€ í–‰ë™ì—ë„ ë§ˆìŒì´ ì›€ì§ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ 1ë¶„ì´ ë‚´ì¼ì˜ ë£¨í‹´ìœ¼ë¡œ ì´ì–´ì§ˆ ê±°ì˜ˆìš”.",
        "facilitator": "ì‹œì‘ì€ ì–¸ì œë‚˜ ì‘ì„ìˆ˜ë¡ ì¢‹ì•„ìš”. ë¶€ë‹´ ì—†ì´ í•œ ê±¸ìŒë§Œ ë‚´ë”›ì–´ë´ìš”.",
        "signal": "ì§€ê¸ˆ íë¦„ì´ ì•„ì£¼ ì¢‹ì•„ìš”. ì´ ëŠë‚Œ ê·¸ëŒ€ë¡œ ì´ì–´ê°€ë©´ ì¶©ë¶„í•©ë‹ˆë‹¤."
    }[pt]

    return {
        "consistency": consistency,
        "failure_reasons": failure_reasons,
        "daily_pattern": daily_pattern,
        "courage": courage
    }

# ===== recommendation ìƒì„± (ì›ë³¸ ìœ ì§€) =====
def generate_recommendations(habits):
    recs = []
    for h in habits:
        logs = h.get("habit_log", [])
        total = len(logs)
        fails = sum(1 for l in logs if not l.get("completed"))
        rate = (total - fails) / total * 100 if total else 0
        start, end = h.get("start_time") or "07:00", h.get("end_time") or "07:30"
        name = h.get("name") or "ìŠµê´€"
        if rate < 50:
            new_end = add_minutes(start, max(15, minutes_between(start, end) - 15))
            name = name + " (ê°€ë²¼ìš´ ë²„ì „)"
        elif rate >= 80:
            new_end = end
            name = name + " (ìœ ì§€)"
        else:
            new_end = end
        recs.append({
            "habit_id": h.get("habit_id"),
            "name": name,
            "start_time": start,
            "end_time": new_end,
            "day_of_week": h.get("day_of_week", [1,2,3,4,5])
        })
    return recs

# ===== ë©”ì¸ =====
def main():
    for filename in os.listdir(INPUT_DIR):
        if not filename.endswith(".json"): continue
        path = os.path.join(INPUT_DIR, filename)
        data = json.load(open(path, "r", encoding="utf-8"))
        user_id, nickname = data["user_id"], data.get("nickname", str(data["user_id"]))
        report_type = (data.get("type") or "monthly").lower()
        if report_type not in ("weekly", "monthly"): report_type = "monthly"
        output_dir = OUTPUT_DIRS[report_type]
        habits_all = data.get("habits", [])
        active_habits = [h for h in minutes_filter_copy(habits_all) if h.get("habit_log")]
        if not active_habits: continue
        parsed = {}

        # ê³µí†µ êµ¬ì„±ìš”ì†Œ (weekly/monthly ë™ì¼)
        top_fail = compute_per_habit_top_failure_reasons(active_habits, 2)
        parsed["top_failure_reasons"] = top_fail

        rate = compute_overall_success_rate(active_habits)
        level = consistency_level_from_rate(rate)
        parsed["consistency_index"] = {
            "success_rate": round(rate, 1),
            # "level": level,
            # "thresholds": CONSISTENCY_THRESHOLDS,
            "display_message": f"ê¾¸ì¤€í•¨ ì§€ìˆ˜: {level}" + (" ğŸ”¥" if level=="ë†’ìŒ" else (" ğŸ™‚" if level=="ë³´í†µ" else " ğŸŒ§ï¸"))
        }

        parsed["summary"] = generate_summary(nickname, active_habits, top_fail, rate)
        parsed["recommendation"] = generate_recommendations(active_habits)

        os.makedirs(output_dir, exist_ok=True)
        json.dump(parsed, open(os.path.join(output_dir, f"user_{user_id}_{nickname}_{report_type}_report.json"), "w", encoding="utf-8"), ensure_ascii=False, indent=2)
        print(f"âœ… {nickname} {report_type} ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ")

if __name__ == "__main__":
    main()